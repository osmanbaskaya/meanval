{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example 1\n",
    "embedding_ph = tf.placeholder(tf.float32, [5, 10]) \n",
    "embeddings = tf.Variable(tf.random_uniform([5, 10], -1.0, 1.0), dtype=tf.float32, name=\"embeddings\")\n",
    "embeddings_init = embeddings.assign(embedding_ph)\n",
    "shape = tf.reduce_sum(embeddings_init)\n",
    "embedding_weights = np.ones((5, 10))\n",
    "sess.run([shape], feed_dict={embedding_ph: embedding_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 3, 'b': 1, 'c': 2})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"a\", \"b\", \"a\", \"a\", \"c\", \"c\"]\n",
    "counter = Counter(words)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 3, 'c': 2})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_list = [w for w, f in counter.items() if f < 2]\n",
    "list(map(counter.pop, remove_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "education = tf.contrib.layers.sparse_column_with_keys(\n",
    "  column_name=\"gender\", keys=[\"Master\", \"Bachelor\"])\n",
    "gender = tf.contrib.layers.sparse_column_with_keys(\n",
    "  column_name=\"gender\", keys=[\"Female\", \"Male\"])\n",
    "education_x_occupation = tf.contrib.layers.crossed_column([gender, education], hash_bucket_size=int(1e4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CrossedColumn(columns=(_SparseColumnKeys(column_name='gender', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('Female', 'Male'), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string), _SparseColumnKeys(column_name='gender', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('Master', 'Bachelor'), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string)), hash_bucket_size=10000, hash_key=None, combiner='sum', ckpt_to_load_from=None, tensor_name_in_ckpt=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_x_occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import urllib\n",
    "test_file = tempfile.NamedTemporaryFile()\n",
    "urllib.request.urlretrieve(\"http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.test\", test_file.name)\n",
    "\n",
    "import pandas as pd\n",
    "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "           \"income_bracket\"]\n",
    "df = pd.read_csv(test_file, names=COLUMNS, skipinitialspace=True, skiprows=1)\n",
    "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "                       \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
    "\n",
    "categorical_cols = {k: tf.SparseTensor(\n",
    "      indices=[[i, 0] for i in range(df[k].size)],\n",
    "      values=df[k].values,\n",
    "      dense_shape=[df[k].size, 1])\n",
    "                      for k in CATEGORICAL_COLUMNS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "result = sess.run(categorical_cols)\n",
    "#categorical_cols['education'].eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Tensorflow\n",
    "https://www.tensorflow.org/get_started/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "adder_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.,  6.], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(adder_node, {a: [5], b:[3, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30000001], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = tf.Variable([.3], tf.float32, name='Weight')\n",
    "b = tf.Variable([-.3], tf.float32, name=\"Bias\")\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(linear_model, {x: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  0.        ,   1.68999982,   6.75999928,  15.21000099], dtype=float32), 23.66]\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run([squared_deltas, loss], {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([W, b]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_RealValuedColumn(column_name='x', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/j1/vq1fgd095n75n3lcjx25nv1r0000gn/T/tmplmznnfvo\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/j1/vq1fgd095n75n3lcjx25nv1r0000gn/T/tmplmznnfvo', '_num_ps_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_checkpoints_steps': None, '_evaluation_master': '', '_num_worker_replicas': 0, '_environment': 'local', '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a28d7f0>, '_is_chief': True, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': 600, '_task_id': 0, '_task_type': None, '_session_config': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/j1/vq1fgd095n75n3lcjx25nv1r0000gn/T/tmplmznnfvo/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 7.51949535745\n",
      "INFO:tensorflow:Saving checkpoints for 5 into /var/folders/j1/vq1fgd095n75n3lcjx25nv1r0000gn/T/tmplmznnfvo/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.123233706793.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-05:02:35\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/j1/vq1fgd095n75n3lcjx25nv1r0000gn/T/tmplmznnfvo/model.ckpt-5\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-05:02:36\n",
      "INFO:tensorflow:Saving dict for global step 5: global_step = 5, loss = 0.0214368\n",
      "{'loss': 0.021436835, 'global_step': 5}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W*features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # ModelFnOps connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.contrib.learn.ModelFnOps(\n",
    "      mode=mode, predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model)\n",
    "# define our data set\n",
    "x = np.array([1., 2., 3., 4.])\n",
    "y = np.array([0., -1., -2., -3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x}, y, 4, num_epochs=10)\n",
    "\n",
    "# train\n",
    "estimator.fit(input_fn=input_fn, steps=5)\n",
    "# evaluate our model\n",
    "print(estimator.evaluate(input_fn=input_fn, steps=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2df056a799ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_fn' is not defined"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "a = input_fn()[0]\n",
    "list(sess.run(a['x']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### New functionalities\n",
    "\n",
    "- https://www.tensorflow.org/get_started/get_started\n",
    "    - tf.group(optimizer.minimize(loss),tf.assign_add(global_step, 1))\n",
    "    - tf.contrib.learn.ModelFnOps\n",
    "    - tf.contrib.learn.io.numpy_input_fn({\"x\": x}, y, 4, num_epochs=1000)\n",
    "- https://www.tensorflow.org/get_started/mnist/mechanics\n",
    "    - with tf.Graph().as_default(): (command that indicates all of the built ops are to be associated with the default global tf.Graph instance.)\n",
    "    - tf.nn.in_top_k(logits, labels, 1)\n",
    "    - tf.to_int64(labels)\n",
    "- Other useful functions\n",
    "    - tf.reset_default_graph()\n",
    "    - [n.name for n in tf.get_default_graph().as_graph_def().node]  # Print nodes in the default graph.\n",
    "    - tf.get_default_session()\n",
    "    - run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)  # Execution stats\n",
    "    - tf.gfile.Exists(FLAGS.log_dir)\n",
    "    - tf.gfile.DeleteRecursively(FLAGS.log_dir)\n",
    "    - tf.gfile.MakeDirs(FLAGS.log_dir)\n",
    "    - tf.contrib.learn.datasets.base.load_csv_with_header(filename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float32)\n",
    "    - tf.contrib.layers.real_valued_column(\"\", dimension=4)\n",
    "    - tf.contrib.layers.crossed_column([age_buckets, education, occupation], hash_bucket_size=int(1e6))\n",
    "    - with tf.device(\"/cpu:0\"):  # Pin a variable to CPU.\n",
    "    - w2 = tf.Variable(weights.initialized_value(), name=\"w2\")  # `tf.global_variables_initializer()` initializes variables in parallel, so more attention is required if one variable uses other variable's value. \n",
    "    - tf.variable_scope(\"foo\", initializer=tf.constant_initializer(0.4))  # default initializer\n",
    "    - tf.train.match_filenames_once\n",
    "    - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\", reuse=True):\n",
    "    a = tf.get_variable(\"v\", [1])\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.variable_scope(\"bar\"):\n",
    "    b = tf.get_variable(\"b\", [5])\n",
    "    with tf.variable_scope(\"baz\") as other_scope:\n",
    "        b = tf.get_variable(\"b\", [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\") as foo_scope:\n",
    "    assert foo_scope.name == \"foo\"\n",
    "with tf.variable_scope(\"bar\", reuse=True):\n",
    "    b = tf.get_variable(\"b\", [5])\n",
    "    with tf.variable_scope(\"baz\") as other_scope:\n",
    "        #assert other_scope.reuse == False, \"reuse not false\"\n",
    "        b = tf.get_variable(\"b\", [5])\n",
    "#sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ControlDependenciesController',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_function',\n",
       " '_add_op',\n",
       " '_apply_device_functions',\n",
       " '_as_graph_def',\n",
       " '_as_graph_element_locked',\n",
       " '_attr_scope',\n",
       " '_attr_scope_map',\n",
       " '_building_function',\n",
       " '_c_graph',\n",
       " '_check_not_finalized',\n",
       " '_collections',\n",
       " '_colocation_stack',\n",
       " '_container',\n",
       " '_control_dependencies_for_inputs',\n",
       " '_control_dependencies_stack',\n",
       " '_control_flow_context',\n",
       " '_current_control_dependencies',\n",
       " '_default_original_op',\n",
       " '_device_function_stack',\n",
       " '_finalized',\n",
       " '_functions',\n",
       " '_get_control_flow_context',\n",
       " '_get_function',\n",
       " '_gradient_override_map',\n",
       " '_graph_def_versions',\n",
       " '_handle_deleters',\n",
       " '_handle_feeders',\n",
       " '_handle_movers',\n",
       " '_handle_readers',\n",
       " '_is_function',\n",
       " '_kernel_label_map',\n",
       " '_last_id',\n",
       " '_lock',\n",
       " '_name_stack',\n",
       " '_names_in_use',\n",
       " '_next_id',\n",
       " '_next_id_counter',\n",
       " '_nodes_by_id',\n",
       " '_nodes_by_name',\n",
       " '_op_to_kernel_label_map',\n",
       " '_original_op',\n",
       " '_pop_control_dependencies_controller',\n",
       " '_push_control_dependencies_controller',\n",
       " '_record_op_seen_by_control_dependencies',\n",
       " '_registered_ops',\n",
       " '_seed',\n",
       " '_set_control_flow_context',\n",
       " '_unfeedable_tensors',\n",
       " '_unfetchable_ops',\n",
       " '_unsafe_unfinalize',\n",
       " '_version',\n",
       " 'add_to_collection',\n",
       " 'add_to_collections',\n",
       " 'as_default',\n",
       " 'as_graph_def',\n",
       " 'as_graph_element',\n",
       " 'building_function',\n",
       " 'clear_collection',\n",
       " 'colocate_with',\n",
       " 'container',\n",
       " 'control_dependencies',\n",
       " 'create_op',\n",
       " 'device',\n",
       " 'finalize',\n",
       " 'finalized',\n",
       " 'get_all_collection_keys',\n",
       " 'get_collection',\n",
       " 'get_collection_ref',\n",
       " 'get_name_scope',\n",
       " 'get_operation_by_name',\n",
       " 'get_operations',\n",
       " 'get_tensor_by_name',\n",
       " 'gradient_override_map',\n",
       " 'graph_def_versions',\n",
       " 'is_feedable',\n",
       " 'is_fetchable',\n",
       " 'name_scope',\n",
       " 'prevent_feeding',\n",
       " 'prevent_fetching',\n",
       " 'seed',\n",
       " 'unique_name',\n",
       " 'version']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainable_variables', 'variables']\n",
      "[<tf.Variable 'embeddings:0' shape=(5, 10) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "\n",
    "print(g.get_all_collection_keys())\n",
    "print(g.get_collection(\"trainable_variables\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.parse_example?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
